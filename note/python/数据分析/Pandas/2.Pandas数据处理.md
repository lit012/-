# Pandas数据处理

## 格式转换

### 字典转换为dataframe

#### 无嵌套单个字典转换

```python
import pandas as pd

# 示例字典
data = {
    'name': 'Alice',
    'age': '25',
    'city': 'New York'
}

# 转换为 DataFrame
df = pd.DataFrame([data])  # 使用列表将字典包裹起来

print(df)
```

```bash
   name age      city
0  Alice  25  New York
```

#### 无嵌套多个字典转换

```python
import pandas as pd

# 示例字典列表
data = [
    {'name': 'Alice', 'age': 25, 'city': 'New York'},
    {'name': 'Bob', 'age': 30, 'city': 'Los Angeles'},
    {'name': 'Charlie', 'age': 35, 'city': 'Chicago'}
]

# 转换为 DataFrame
df = pd.DataFrame(data)

print(df)
```

```bash
      name  age         city
0    Alice   25     New York
1      Bob   30  Los Angeles
2  Charlie   35      Chicago
```

### dataframe转换为numpy

```python
# 将 DataFrame 转换为 NumPy 数组
X_np = self.X.values  # 转换特征矩阵
y_np = self.y.values  # 转换目标变量
```

## 数据检验

### dataframe检验相同列有几类不同数据

使用unique()获取包含这些值的列表，然后输出列表长度。

```python
import pandas as pd

# 创建示例 DataFrame
df = pd.DataFrame({
    'A': [1, 2, 2, 3, 4, 4],
    'B': ['apple', 'banana', 'apple', 'banana', 'cherry', 'apple']
})

# 获取列 'A' 中不同值
unique_values_A = df['A'].unique()
count_A = len(unique_values_A)
print("列 'A' 中不同值:", unique_values_A, "数量:", count_A)

# 获取列 'B' 中不同值
unique_values_B = df['B'].unique()
count_B = len(unique_values_B)
print("列 'B' 中不同值:", unique_values_B, "数量:", count_B)
```

```bash
列 'A' 中不同值: [1 2 3 4] 数量: 4
列 'B' 中不同值: ['apple' 'banana' 'cherry'] 数量: 3
```

### dataframe检验是否有空数据

在 pandas 中，你可以使用 isnull() 或 isna() 方法结合 any() 来检查 DataFrame 中是否有空值。s

```python
import pandas as pd

# 示例 DataFrame
data = {
    'id': [1, 2, 3],
    'name': ['Alice', None, 'Charlie'],
    'age': [25, 30, None]
}

df = pd.DataFrame(data)

# 检查是否有空值
has_null = df.isnull().any().any()  # 检查整个 DataFrame

print("DataFrame 中是否有空值:", has_null)

# 检查特定列是否有空值，例如 'name'
has_null_name = df['name'].isnull().any()
print("'name' 列是否有空值:", has_null_name)
```

```bash
DataFrame 中是否有空值: True
'name' 列是否有空值: True
```

- isnull() 会返回一个与 DataFrame 相同形状的布尔值 DataFrame，其中空值为 True。
- any() 方法用于检查布尔值 DataFrame 中是否有 True 值。
- 第一个 any() 检查每一列是否有空值，返回一个布尔 Series。
- 第二个 any() 检查整个 Series 是否有 True 值。
- 如果只想检查特定列，可以直接对该列使用 isnull() 和 any()。


### dataframe检验是否有过大值

#### 条件筛选

你可以使用条件筛选来查找特定列中的极大值。例如，如果你认为某列的值超过 1000 是过大的值，可以这样做：

```python
# 假设你要检查 'Length' 列
large_values = data[data['Length'] > 1000]
print(large_values)
```

```python
# 将 'Length' 列中大于 1000 的值替换为 NaN
data.loc[data['Length'] > 1000, 'Length'] = np.nan
```

#### 四分位数或偏差值判断

可以使用 Z-score 或 IQR（四分位数间距）来识别异常值：

```python
from scipy import stats

z_scores = stats.zscore(data['Length'])
abs_z_scores = np.abs(z_scores)
outliers = data[abs_z_scores > 3]  # 取绝对值大于3的Z-score
print(outliers)
```

```python
import pandas as pd
import numpy as np
from scipy import stats

# 假设 data 是你的 DataFrame

for column in data.columns:
    # 计算 Z-score，只对非空值计算
    z_scores = stats.zscore(data[column].dropna())
    abs_z_scores = np.abs(z_scores)
    
    # 创建与原始数据长度相同的布尔数组
    is_outlier = np.zeros(data[column].shape, dtype=bool)  # 创建全 False 的布尔数组
    
    # 获取非空值的索引
    non_nan_index = data[column].dropna().index
    
    # 将大于 3 的 Z-score 对应的索引标记为 True
    is_outlier[non_nan_index[abs_z_scores > 3]] = True
    
    # 将异常值设为 NaN（直接在原数据上）
    data[column] = np.where(is_outlier, np.nan, data[column])
    
    # 计算当前列的均值，忽略 NaN 值
    mean_value = data[column].mean()
    
    # 用均值填充 NaN
    data[column].fillna(mean_value, inplace=True)
```

![z_score](img2/01.png)

```python
Q1 = data['Length'].quantile(0.25)
Q3 = data['Length'].quantile(0.75)
IQR = Q3 - Q1

# 定义异常值的界限
lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR
outliers = data[(data['Length'] < lower_bound) | (data['Length'] > upper_bound)]
print(outliers)
```



## 数据过滤

### dataframe删除多余数据

#### drop_duplicates()根据列值去重复行

```python
import pandas as pd

# 示例 DataFrame
data = {
    'id': [1, 2, 2, 3, 4, 4],
    'name': ['Alice', 'Bob', 'Bob', 'Charlie', 'David', 'David'],
    'age': [25, 30, 30, 35, 40, 40]
}

df = pd.DataFrame(data)

# 打印原始 DataFrame
print("原始 DataFrame:")
print(df)

# 根据 'id' 列去重，但不更新索引值
df_unique = df.drop_duplicates(subset='id')

# 打印去重后的 DataFrame
print("\n去重后的 DataFrame:")
print(df_unique)
```

```bash
原始 DataFrame:
   id     name  age
0  1   Alice   25
1  2     Bob   30
2  2     Bob   30
3  3 Charlie   35
4  4   David   40
5  4   David   40

去重后的 DataFrame:
   id     name  age
0  1   Alice   25
1  2     Bob   30
3  3 Charlie   35
4  4   David   40
```

如果需要更新索引值，可以使用reset_index(drop=True)

```python
# 根据 'id' 列去重并重置索引
df_unique = df.drop_duplicates(subset='id').reset_index(drop=True)
```

#### drop()根据列名去除多余列

drop(index=[...])或者drop(columns=[...])可以去除不想要的行或者列。

```python
import pandas as pd

# 示例 DataFrame
data = {
    'id': [1, 2, 3],
    'name': ['Alice', 'Bob', 'Charlie'],
    'age': [25, 30, 35],
    'city': ['New York', 'Los Angeles', 'Chicago']
}

df = pd.DataFrame(data)

# 打印原始 DataFrame
print("原始 DataFrame:")
print(df)

# 删除不需要的列，例如 'age' 和 'city'
df_dropped = df.drop(columns=['age', 'city'])

# 打印删除后的 DataFrame
print("\n删除后的 DataFrame:")
print(df_dropped)
```

```bash
原始 DataFrame:
   id     name  age         city
0  1   Alice   25     New York
1  2     Bob   30  Los Angeles
2  3 Charlie   35      Chicago

删除后的 DataFrame:
   id     name
0  1   Alice
1  2     Bob
2  3 Charlie
```

#### df.dropna()删除包含空值的行

```python
import pandas as pd

# 示例 DataFrame
data = {
    'id': [1, 2, 3, 4],
    'name': ['Alice', None, 'Charlie', 'David'],
    'age': [25, 30, None, 40]
}

df = pd.DataFrame(data)

# 打印原始 DataFrame
print("原始 DataFrame:")
print(df)

# 去掉包含空值的行
df_cleaned = df.dropna()

# 打印去掉空值后的 DataFrame
print("\n去掉空值后的 DataFrame:")
print(df_cleaned)
```

```bash
原始 DataFrame:
   id     name   age
0  1   Alice  25.0
1  2    None  30.0
2  3 Charlie   NaN
3  4   David  40.0

去掉空值后的 DataFrame:
   id     name   age
0  1   Alice  25.0
3  4   David  40.0
```

如果你只想根据特定列去掉包含空值的行，可以使用 subset 参数：

```python
df_cleaned = df.dropna(subset=['name', 'age'])
```

### dataframe保存部分数据

#### 筛选列值符合条件的数据

```python
import pandas as pd

# 创建示例 DataFrame
df = pd.DataFrame({
    'A': [1, 2, 2, 3, 4, 4],
    'B': ['apple', 'banana', 'apple', 'banana', 'cherry', 'apple']
})

# 使用 loc 进行筛选
filtered_df = df.loc[df['B'].isin(['apple', 'banana'])]
print(filtered_df)
```

### 数据替换

#### 将空值数据替换为平均值

将所有列的空值替换为平均值。

`mean()`方法计算出每列的平均值。

使用`fillna()`方法将该列的`NaN`值替换为计算出的平均值，通过设置`inplace=True`直接在原DataFrame上进行修改。

```python
import pandas as pd

# 生成一个示例DataFrame
data = {
    'col1': [1, float('NaN'), 3, 4, float('NaN')],
    'col2': [5, 6, float('NaN'), 8, 9]
}
df = pd.DataFrame(data)

# 遍历每一列，将NaN值填充为该列的平均值
for column in df.columns:
    mean_value = df[column].mean()
    df[column].fillna(mean_value, inplace=True)

print(df)
```

如果你的数据中存在其他类型的缺失值表示方式（比如None等），可能需要先将它们统一转换为NaN再进行上述操作。例如：

```python
df = df.replace({None: float('NaN')})
```





## 数据保存

### 保存在excel

首先确保安装了`openpyxl` 或 `xlrd` 库，这些库用于处理 Excel 文件。

```bash
pip install openpyxl xlrd
```

**(1) 读取excel**

```python
import pandas as pd

# 读取 Excel 文件
df = pd.read_excel('file.xlsx', sheet_name='Sheet1')  # 指定表单名称

# 打印 DataFrame
print(df)
```

**(2) 写入excel**

```python
# 将 DataFrame 写入 Excel 文件
df.to_excel('output.xlsx', sheet_name='Sheet1', index=False)  # index=False 不写入索引列
```

**(3) 多表单读取**

```python
# 读取所有表单
dfs = pd.read_excel('file.xlsx', sheet_name=None)  # 返回一个字典，键为表单名称，值为对应的 DataFrame

# 打印所有表单的 DataFrame
for sheet_name, data in dfs.items():
    print(f"Sheet: {sheet_name}")
    print(data)
```

**(4) 多表单写入**

```python
with pd.ExcelWriter('output_multiple_sheets.xlsx') as writer:
    df1.to_excel(writer, sheet_name='Sheet1', index=False)
    df2.to_excel(writer, sheet_name='Sheet2', index=False)
```

### 保存在csv

**(1) read_csv()**

```python
import pandas as pd

# 指定CSV文件路径
file_path = 'your_file.csv'

# 读取CSV文件
df = pd.read_csv(file_path)

# 显示DataFrame的前几行
print(df.head())
```

**(2) to_csv()**

```python
# 指定要写入的CSV文件路径
output_file_path = 'output_file.csv'

# 将DataFrame写入CSV文件
df.to_csv(output_file_path, index=False)  # 设置index=False以避免将行索引写入文件
```


### 保存在mysql

#### 安装库

```bash
pip install pymysql
```

#### 创建数据库

```sql
-- 创建数据库
CREATE DATABASE IF NOT EXISTS your_database;

-- 使用数据库
USE your_database;

-- 创建表
CREATE TABLE IF NOT EXISTS your_table (
    id INT AUTO_INCREMENT PRIMARY KEY,
    title VARCHAR(255),
    url VARCHAR(255),
    date DATE,
    imgCount INT,
    type VARCHAR(50),
    source VARCHAR(100),
    edit VARCHAR(100),
    artical_one TEXT
);
```

或者你可以在python中创建数据库。

```python
import pymysql

# 连接到MySQL服务器
connection = pymysql.connect(
    host='localhost',
    user='your_username',
    password='your_password'
)

cursor = connection.cursor()

# 创建数据库
cursor.execute("CREATE DATABASE IF NOT EXISTS your_database")
cursor.execute("USE your_database")

# 创建表
cursor.execute("""
    CREATE TABLE IF NOT EXISTS your_table (
        id INT AUTO_INCREMENT PRIMARY KEY,
        title VARCHAR(255),
        url VARCHAR(255),
        date DATE,
        imgCount INT,
        type VARCHAR(50),
        source VARCHAR(100),
        edit VARCHAR(100),
        artical_one TEXT
    )
""")

# 关闭连接
cursor.close()
connection.close()
```

#### 数据写入数据库

```python
import pandas as pd
import pymysql

# 示例数据
data = {
    'title': ['新疆库车市发生5.5级地震'],
    'url': ['http://society.people.com.cn/n1/2024/1026/c1008-40347782.html'],
    'date': ['2024-10-26 18:23:24'],
    'imgCount': [0],
    'type': ['society'],
    'source': ['新华网'],
    'edit': ['王静、岳弘彬'],
    'artical_one': ['新华社乌鲁木齐10月26日电（记者马锴、张瑜）26日16时35分，新疆阿克苏地区库车市（北纬40.98度，东经83.93度）发生5.5级地震，震源深度10公里。截至当日17时，暂无人员伤亡报告。']
}

# 创建 DataFrame
df = pd.DataFrame(data)

# 连接到MySQL数据库
connection = pymysql.connect(
    host='localhost',
    user='your_username',
    password='your_password',
    database='your_database'
)

try:
    with connection.cursor() as cursor:
        # 插入数据
        insert_query = """
            INSERT INTO your_table (title, url, date, imgCount, type, source, edit, artical_one)
            VALUES (%s, %s, %s, %s, %s, %s, %s, %s)
        """
        
        # 批量插入数据
        cursor.executemany(insert_query, df.values.tolist())
    
    # 提交更改
    connection.commit()
    print("数据已成功写入MySQL")

finally:
    # 关闭连接
    connection.close()
```

- 连接到数据库：使用 pymysql.connect 建立连接。
- 创建数据库和表：通过 SQL 语句创建数据库和表。
- 插入数据：使用 INSERT INTO 语句将数据插入表中。
- 批量插入：使用 executemany 方法可以一次性插入多条记录。
- 提交更改：调用 commit() 来保存数据。