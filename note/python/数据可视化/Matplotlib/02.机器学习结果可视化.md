# 对机器学习的结果进行可视化

## 回归结果可视化

### 散点图和残差图

散点图的点应该沿着对角线（y = x）分布。这表示模型的预测值与真实值相等，模型预测非常准确。

如果点大多集中在对角线的上方，说明模型的预测值普遍偏高（即高估了真实值）；如果点大多集中在对角线的下方，说明模型的预测值普遍偏低（即低估了真实值）。

如果点分布得很分散，说明模型的预测不稳定，可能存在较大的误差。较为集中的点表示模型较为稳定。

残差图的残差应该随机分布在零线（y = 0）附近，没有明显的模式。这表明模型的预测误差是随机的，没有系统性的偏差。如果残差图中出现明显的趋势（例如，随着预测值的增加，残差也增加），说明模型在某些值区间表现较差，这可能是模型没有捕捉到数据中的某些特征。

如果残差的散布随着预测值的增大而增大，说明模型的预测不确定性随预测值的增加而增加，这可能暗示模型在处理某些数据点时表现较差。



```python
import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import mean_squared_error, r2_score

# 假设你已经有了模型和验证数据
# 这里是模型对验证集的预测值
y_pred = model.predict(X_val)  # 使用模型进行预测
y_true = y_val  # 真实值

# 计算模型性能指标
mse = mean_squared_error(y_true, y_pred)  # 计算均方误差（MSE）
r2 = r2_score(y_true, y_pred)  # 计算决定系数（R²）

# 打印性能指标
print(f'MSE: {mse}, R²: {r2}')  # 输出 MSE 和 R² 的值

# 创建绘图
plt.figure(figsize=(12, 6))  # 设置图形的大小

# 绘制真实值与预测值的散点图
plt.subplot(1, 2, 1)  # 创建一个1行2列的子图，并选择第1个
plt.scatter(y_true, y_pred, alpha=0.5)  # 绘制散点图，透明度设置为0.5
plt.plot([y_true.min(), y_true.max()], [y_true.min(), y_true.max()], 'r--')  # 绘制对角线（理想情况下，预测值等于真实值）
plt.title('True vs Predicted')  # 设置标题
plt.xlabel('True Values')  # X轴标签
plt.ylabel('Predicted Values')  # Y轴标签

# 绘制残差图
residuals = y_pred - y_true  # 计算残差，即预测值减去真实值
plt.subplot(1, 2, 2)  # 创建一个1行2列的子图，并选择第2个
plt.scatter(y_pred, residuals, alpha=0.5)  # 绘制残差图
plt.axhline(0, color='r', linestyle='--')  # 绘制一条水平的红色虚线，表示残差为零的水平线
plt.title('Residuals')  # 设置标题
plt.xlabel('Predicted Values')  # X轴标签
plt.ylabel('Residuals')  # Y轴标签

plt.tight_layout()  # 调整布局，使子图之间不重叠
plt.show()  # 显示图形
```